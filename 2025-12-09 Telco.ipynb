{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efd9d788-bb05-409a-96ac-5eed7b75822a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "file_location = \"/Workspace/Users/ts149509@student.sgh.waw.pl/Data/telco.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "from pyspark.sql.functions import trim, when \n",
    "\n",
    "#df_tc_dbl = df.withColumn('TotalCharges', col('TotalCharges').cast('double'))\n",
    "\n",
    "#display(df.select(trim(col(\"TotalCharges\"))))\n",
    "#.cast('double')\n",
    "df_tc_dbl = df.withColumn('TotalCharges', trim(col(\"TotalCharges\")))\n",
    "\n",
    "#df_tc_dbl['TotalCharges Trimmed'] = df_tc_dbl['TotalCharges Trimmed'].apply(lambda x: float(x) if x != '' else 0)\n",
    "#df_tc_dbl.replace()\n",
    "#df_tc_dbl['TotalCharges Trimmed'] = df_tc_dbl['TotalCharges Trimmed'].replace('', 0)\n",
    "\n",
    "df_tc_dbl = df.withColumn(\"TotalCharges\", \\\n",
    "       when(col('TotalCharges')==\" \" , None) \\\n",
    "          .otherwise(col('TotalCharges')))\n",
    "df_tc_dbl = df_tc_dbl.withColumn('TotalCharges', col('TotalCharges').cast('double'))\n",
    "\n",
    "#df_tc_dbl = df.withColumn('TotalCharges', df.select(trim(col(\"TotalCharges\"))).cast('double'))\n",
    "display(df_tc_dbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc631aad-1a9b-40a6-9bb4-a6e9d207a209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_grp_contract_phone = df_tc_dbl.groupBy('Contract', 'PhoneService').count().sort(['Contract', 'PhoneService'])\n",
    "#df_grp_contract_phone.show()\n",
    "display(df_grp_contract_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2143096d-0c89-4e7b-b0a6-46a5d43a6362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round, avg, count\n",
    "# Aggregate: Contract, PhoneService, Avg MonthlyCharges (rounded), count (rows)\n",
    "df_agg = df_tc_dbl.groupBy('Contract', 'PhoneService') \\\n",
    "    .agg(round(avg('MonthlyCharges'), 2).alias('Avg MonthlyCharges'), count('Contract').alias('Count'))\n",
    "display(df_agg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f0f3c1-2612-47d6-8365-b54ce88fc142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "type(df_agg.collect())\n",
    "#df_agg.collect()\n",
    "my_res = None\n",
    "for row in df_agg.collect():\n",
    "  #print(row)\n",
    "  row_dict = row.asDict()\n",
    "  #print(type(row_dict))\n",
    "  if row_dict['Contract'] == 'One year' and row_dict['PhoneService'] == 'Yes':\n",
    "    my_res = row_dict['Avg MonthlyCharges']\n",
    "    print(type(my_res))\n",
    "    print(my_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01875ec9-6e98-451d-ba5e-1b1f9edaa70b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_selection = df_tc_dbl.select('Contract', 'PhoneService', 'MonthlyCharges')\n",
    "df_filtered = df_selection.filter((df_selection['Contract'] == 'One year') | (df_selection['PhoneService'] == 'Yes'))  # OR\n",
    "\n",
    "df_filtered = df_selection.filter((df_selection['Contract'] == 'One year') & (df_selection['PhoneService'] == 'Yes'))  # AND\n",
    "\n",
    "display(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38299d46-b828-4bd9-998c-b56d6d421640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find rows for which TotalCharges are not equal to MonthlyCharges * tenure\n",
    "\n",
    "# ===\n",
    "\n",
    "df_res = df_tc_dbl.withColumn('Tenure x Monthly Charges', round(col('tenure') * col('MonthlyCharges'), 2))\n",
    "df_res = df_res.withColumn('Diff Charges', round(col('Tenure x Monthly Charges') - col('TotalCharges'), 2))\n",
    "#display(df_res)\n",
    "eq = df_res.filter(col('Diff Charges') == 0).count()\n",
    "print(f'Equal: {eq}')\n",
    "df_res = df_res.filter(col('Diff Charges') != 0)\n",
    "neq = df_res.count()\n",
    "print(f'Not Equal: {neq}')\n",
    "#display(df_res)\n",
    "from pyspark.sql.functions import desc\n",
    "df_res2 = df_res.sort(desc('Diff Charges')).limit(10)\n",
    "display(df_res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b125a769-1d8e-4b9e-a9ae-34bef2a4499f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def convert_contract(cntr):\n",
    "    cntr = cntr.replace('Month-to-month', 'monthly')\n",
    "    cntr = cntr.replace('One', '1')\n",
    "    cntr = cntr.replace('Two', '2')\n",
    "    return cntr\n",
    "\n",
    "df_res3 = df_res.withColumn('Contract Short', convert_contract(col('Contract')))\n",
    "display(df_res3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e951dc86-53b3-412f-8911-adb4fa97bba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TODO: Check if customers with dependents pay on average more than those without dependents. The answer should be a single bool (True or False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0e64a47-d16d-4157-a134-5023d6e098f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if customers with dependents pay on average more than those without dependents. The answer should be a single bool (True or False)\n",
    "\n",
    "from pyspark.sql.functions import avg, mean, col\n",
    "\n",
    "df_res3.groupBy('Dependents').agg(mean('MonthlyCharges').alias('Avg Monthly Charge')).display()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2025-12-09 Telco",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
