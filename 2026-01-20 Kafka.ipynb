{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "698ebc5a-4ed0-4c8d-ad98-3d5b49334a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "705f5363-4b43-43f5-8da8-2b09436334ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "460a615a-cf75-4a46-bc19-36e5b87c2c1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pure Python implementation, spark is not used\n",
    "# bin/kafka-console-producer.sh --broker-list sih-60.cent.uw.edu.pl:49092 --topic bigdata-test-25\n",
    "from kafka import KafkaConsumer\n",
    "import sys\n",
    "import time\n",
    "\n",
    "consumer = KafkaConsumer('bigdata-test-25', bootstrap_servers=['sih-60.cent.uw.edu.pl:49092'], group_id='my_consumer_2')\n",
    "\n",
    "for message in consumer:\n",
    "  print(message.value.decode('utf-8'))\n",
    "  time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4fc40bd-77a3-4b6b-b0a1-4b50abb96720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "movies_df_schema = StructType(\n",
    "  [StructField('movieId', IntegerType()),\n",
    "  StructField('title', StringType()),\n",
    "  StructField('Genres', StringType())]\n",
    ")\n",
    "\n",
    "# File location and type\n",
    "file_location = \"/databricks-datasets/cs110x/ml-1m/data-001/movies.dat\"\n",
    "file_type = 'csv'\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"false\"\n",
    "delimiter = \"::\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_movies = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .schema(movies_df_schema) \\\n",
    "  .load(file_location)\n",
    "\n",
    "#movies_df = df_movies.drop('Genres','empty1','empty2')\n",
    "#df_movies.cache()\n",
    "display(df_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e895b0bb-51c1-45c2-ae2d-6bdf1ec65276",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ./kafka-console-consumer.sh --bootstrap-server sih-60.cent.uw.edu.pl:49092 --topic bigdata-test-25\n",
    "#spark.conf.set(\"spark.sql.streaming.stopActiveRunOnRestart\", True) \n",
    "ds = df_movies \\\n",
    "  .selectExpr(\"CAST(movieId AS STRING)\", \"CAST(title AS STRING) as value\") \\\n",
    "  .write \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"sih-60.cent.uw.edu.pl:49092\") \\\n",
    "  .option(\"topic\", \"bigdata-test-25\") \\\n",
    "  .save()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2026-01-20 Kafka",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
